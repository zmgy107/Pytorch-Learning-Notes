{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8r1RpdnjX29ea3YYnRk3T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zmgy107/Pytorch-Learning-Notes/blob/main/Tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEdeQ1NWIe8G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing a Tensor"
      ],
      "metadata": {
        "id": "vepdkv4gKGcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Directly from data**\n",
        "\n",
        "Tensors can be created directly from data. The data type is automatically inffered"
      ],
      "metadata": {
        "id": "XlcxaK_8KRPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=[[1,2],[3,4]]\n",
        "x_data=torch.tensor(data)\n",
        "# print(x_data)"
      ],
      "metadata": {
        "id": "E3dBim4bJSVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From a NumPy array**\n",
        "\n",
        "Tensors can be created from NumPy arrays."
      ],
      "metadata": {
        "id": "L2cX6757LA7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_array=np.array(data)\n",
        "x_np=torch.from_numpy(np_array)\n",
        "print(\"np_array:\",np_array)\n",
        "print(\"x_np:\",x_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shw2xEn5LRBn",
        "outputId": "a01ab087-a13b-40eb-aa25-22f70bd48e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "np_array: [[1 2]\n",
            " [3 4]]\n",
            "x_np: tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From another tensor**\n",
        "\n",
        "The new tensor retains the properties(shape,datatype) of the argument tensor,unless explicitly overridden."
      ],
      "metadata": {
        "id": "ihY5ndHWMlW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones=torch.ones_like(x_data) # retains tthe properties of x_data\n",
        "print(f\"Ones Tensor:\\n{x_ones}\\n\")\n",
        "\n",
        "x_rand=torch.rand_like(x_data,dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor:\\n{x_rand}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojlh24kyM6nZ",
        "outputId": "98684aae-46f9-4f1d-9ece-27d8a0c9b63b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor:\n",
            "tensor([[1, 1],\n",
            "        [1, 1]])\n",
            "\n",
            "Random Tensor:\n",
            "tensor([[0.0921, 0.3246],\n",
            "        [0.6251, 0.3121]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**With random or constant values:**\n",
        "\n",
        "shape is a tuple of tensor dimensions.In the functionns below,it determines the dimensionality of the output tensor."
      ],
      "metadata": {
        "id": "lsA1XmWfNml9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape=(2,3,)\n",
        "rand_tensor=torch.rand(shape)\n",
        "ones_tensor=torch.ones(shape)\n",
        "zeros_tensor=torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor:\\n{rand_tensor}\\n\")\n",
        "print(f\"Ones Tensor:\\n{ones_tensor}\\n\")\n",
        "print(f\"Zeros Tensor:\\n{zeros_tensor}\")\n",
        "\n",
        "shape_1=(2,3,4)\n",
        "threes_tensor=3*torch.ones(shape_1)\n",
        "print(\"Threes_tensor:\\n\",threes_tensor)\n",
        "# shape(n,m,k) 返回由n个列表构成的元组，每个列表由m个子列表构成，每个子列表由元素个数为k的列表"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlNthLUNN2qZ",
        "outputId": "991025a4-8d50-4bd9-c120-2f48d6ee0b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor:\n",
            "tensor([[0.7025, 0.2520, 0.0922],\n",
            "        [0.4502, 0.3191, 0.7902]])\n",
            "\n",
            "Ones Tensor:\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "\n",
            "Zeros Tensor:\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "Threes_tensor:\n",
            " tensor([[[3., 3., 3., 3.],\n",
            "         [3., 3., 3., 3.],\n",
            "         [3., 3., 3., 3.]],\n",
            "\n",
            "        [[3., 3., 3., 3.],\n",
            "         [3., 3., 3., 3.],\n",
            "         [3., 3., 3., 3.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attributes of a Tensor\n",
        "\n",
        "Tensor attributes describe their shape,datatype,and the device on which they are stored"
      ],
      "metadata": {
        "id": "L5euBes7SgdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor=torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor:{tensor.shape}\")\n",
        "print(f\"DataType of tensor:{tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on:{tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD4suULQSzUY",
        "outputId": "682fb7d6-9196-4d8e-84dc-07c0c005ea1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor:torch.Size([3, 4])\n",
            "DataType of tensor:torch.float32\n",
            "Device tensor is stored on:cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Operations on Tensors\n",
        "\n",
        "tensor operations:arithmetic,linear algebra,matric manipulation(transposing,indexing,slicing),sampling and more\n",
        "\n",
        "By default,tensors are created on the CPU.We need to explicitly move tensors to GPU using \n",
        "\n",
        "```\n",
        "# .to\n",
        "```\n",
        "method(after checking for GPU availability).\n"
      ],
      "metadata": {
        "id": "pB4OLK3SWvP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# move tensor to the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "  tensor=tensor.to(\"cuda\")"
      ],
      "metadata": {
        "id": "IjaFFRacXcXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "try some operations"
      ],
      "metadata": {
        "id": "M8Ra7xJZXwj2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Standard numpy-like indexing and slicing:**"
      ],
      "metadata": {
        "id": "VvSk6bMEX0AK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor=torch.ones(4,4)\n",
        "print(f\"First row:{tensor[0]}\")\n",
        "print(f\"First column:{tensor[:,0]}\")\n",
        "print(f\"Last column:{tensor[...,-1]}\")\n",
        "tensor[:,1]=2\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu6GINktXygd",
        "outputId": "2ce5d25e-af08-4774-ae84-95b9ddf793e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row:tensor([1., 1., 1., 1.])\n",
            "First column:tensor([1., 1., 1., 1.])\n",
            "Last column:tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 2., 1., 1.],\n",
            "        [1., 2., 1., 1.],\n",
            "        [1., 2., 1., 1.],\n",
            "        [1., 2., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Joining tensors**\n",
        "\n",
        "use torch.cat to concatenate a sequence of tensors along a given dimension"
      ],
      "metadata": {
        "id": "JGgqW58SYcwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1=torch.cat([tensor,tensor],dim=1)\n",
        "print(t1)\n",
        "\n",
        "# Dimension out of range (expected to be in range of [-2, 1])\n",
        "t2=torch.cat([tensor,tensor],dim=-2)\n",
        "print(t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNhVaQAEYmtG",
        "outputId": "4e6c25ee-bab5-4032-8f0b-45c3eabb54c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 1., 1., 1., 2., 1., 1.],\n",
            "        [1., 2., 1., 1., 1., 2., 1., 1.],\n",
            "        [1., 2., 1., 1., 1., 2., 1., 1.],\n",
            "        [1., 2., 1., 1., 1., 2., 1., 1.]])\n",
            "tensor([[1., 2., 1., 1.],\n",
            "        [1., 2., 1., 1.],\n",
            "        [1., 2., 1., 1.],\n",
            "        [1., 2., 1., 1.],\n",
            "        [1., 2., 1., 1.],\n",
            "        [1., 2., 1., 1.],\n",
            "        [1., 2., 1., 1.],\n",
            "        [1., 2., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Arithmetic operations**"
      ],
      "metadata": {
        "id": "5KI7hOGNaU7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This computes the matrix multiplication between two tensors.\n",
        "# tensor.T returns the transpose of a tensor\n",
        "y1=tensor @ tensor.T\n",
        "print(\"y1\",y1)\n",
        "\n",
        "y2=tensor.matmul(tensor.T)\n",
        "print(\"y2\",y2)\n",
        "\n",
        "y3=torch.rand_like(y1)\n",
        "# print(\"y3\",y3)\n",
        "torch.matmul(tensor,tensor.T,out=y3)\n",
        "print(\"y3\",y3)\n",
        "\n",
        "# y4 should define first.And it's better to set same dimension of output\n",
        "# y4=torch.rand(2,2) \n",
        "# torch.matmul(tensor.T,tensor,out=y4)\n",
        "# print(\"y4\",y4)\n",
        "\n",
        "\n",
        "# This computes the element-wise product.矩阵间对应位置元素相乘\n",
        "z1=tensor*tensor\n",
        "z2=tensor.mul(tensor)\n",
        "\n",
        "z3=torch.rand_like(tensor)\n",
        "torch.mul(tensor,tensor,out=z3)\n",
        "\n",
        "print(f\"z1:{z1}\")\n",
        "print(f\"z2:{z2}\")\n",
        "print(f\"z3:{z3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RTdoVvTaYw_",
        "outputId": "022e6635-8bc7-4406-f409-7d4c6c5445b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y1 tensor([[7., 7., 7., 7.],\n",
            "        [7., 7., 7., 7.],\n",
            "        [7., 7., 7., 7.],\n",
            "        [7., 7., 7., 7.]])\n",
            "y2 tensor([[7., 7., 7., 7.],\n",
            "        [7., 7., 7., 7.],\n",
            "        [7., 7., 7., 7.],\n",
            "        [7., 7., 7., 7.]])\n",
            "y3 tensor([[7., 7., 7., 7.],\n",
            "        [7., 7., 7., 7.],\n",
            "        [7., 7., 7., 7.],\n",
            "        [7., 7., 7., 7.]])\n",
            "z1:tensor([[1., 4., 1., 1.],\n",
            "        [1., 4., 1., 1.],\n",
            "        [1., 4., 1., 1.],\n",
            "        [1., 4., 1., 1.]])\n",
            "z2:tensor([[1., 4., 1., 1.],\n",
            "        [1., 4., 1., 1.],\n",
            "        [1., 4., 1., 1.],\n",
            "        [1., 4., 1., 1.]])\n",
            "z3:tensor([[1., 4., 1., 1.],\n",
            "        [1., 4., 1., 1.],\n",
            "        [1., 4., 1., 1.],\n",
            "        [1., 4., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Single-element tensors**\n",
        "\n",
        "If you have a one-element tensor, for example by aggregating all values of a tensor into one value, you can convert it to a Python numerical value using item():"
      ],
      "metadata": {
        "id": "Ghgozw7FfjOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agg=tensor.sum()\n",
        "print(f\"agg:{agg}\",type(agg))\n",
        "# .item的作用是将一维的tensor转变类型为数值型\n",
        "agg_item=agg.item()\n",
        "print(agg_item,type(agg_item))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui8s6V-BeTLf",
        "outputId": "dfda1811-9205-4260-8665-240488372452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "agg:20.0 <class 'torch.Tensor'>\n",
            "20.0 <class 'float'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In-place operations**\n",
        "\n",
        "Operations that store the result into the operand are called in-place. They are denoted by a _ suffix. For example: x.copy_(y), x.t_(), will change x."
      ],
      "metadata": {
        "id": "NnZCsfhEgzSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{tensor}\\n\")\n",
        "tensor.add_(2)\n",
        "print(tensor)\n",
        "\n",
        "#x.copy_(y) 把y复制给x\n",
        "tensor_copy=torch.rand_like(tensor)\n",
        "#tensor_copy=torch.rand(2,3) The size of tensor a must match the size of tensor b \n",
        "print(f\"Previous:\\n{tensor_copy}\")\n",
        "tensor_copy.copy_(tensor)\n",
        "print(f\"After copying:\\n{tensor_copy}\")\n",
        "\n",
        "\n",
        "# x.t_() to tensor 转置\n",
        "tensor.t_()\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTXPYy3KhPiy",
        "outputId": "9d1054ec-c9b6-4147-d47a-8ed7b3ce300c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 1., 1.],\n",
            "        [1., 2., 1., 1.],\n",
            "        [1., 2., 1., 1.],\n",
            "        [1., 2., 1., 1.]])\n",
            "\n",
            "tensor([[3., 4., 3., 3.],\n",
            "        [3., 4., 3., 3.],\n",
            "        [3., 4., 3., 3.],\n",
            "        [3., 4., 3., 3.]])\n",
            "Previous:\n",
            "tensor([[0.0865, 0.1951, 0.2321, 0.4184],\n",
            "        [0.1034, 0.4632, 0.3489, 0.6807],\n",
            "        [0.1315, 0.8060, 0.0139, 0.4755],\n",
            "        [0.2423, 0.2225, 0.9654, 0.1262]])\n",
            "After copying:\n",
            "tensor([[3., 4., 3., 3.],\n",
            "        [3., 4., 3., 3.],\n",
            "        [3., 4., 3., 3.],\n",
            "        [3., 4., 3., 3.]])\n",
            "tensor([[3., 3., 3., 3.],\n",
            "        [4., 4., 4., 4.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**\n",
        "\n",
        "In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history. Hence, their use is discouraged."
      ],
      "metadata": {
        "id": "xece6NGQlr4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bridge with Numpy\n",
        "\n",
        "Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other"
      ],
      "metadata": {
        "id": "I65gvddPl4dP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor to NumPy array"
      ],
      "metadata": {
        "id": "aFylwkLQmEJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t=torch.ones(5)\n",
        "print(f\"t:{t}\")\n",
        "n=t.numpy()\n",
        "print(f\"n:{n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3TbcHuxmLID",
        "outputId": "0cd2116d-0311-44d5-bcb4-b8457283687b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t:tensor([1., 1., 1., 1., 1.])\n",
            "n:[1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A change in the tensor reflects in the NumPy array."
      ],
      "metadata": {
        "id": "00-PgUOjmWvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.add_(2)\n",
        "print(f\"t:{t}\")\n",
        "print(f\"n:{n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkFVA5OrmZew",
        "outputId": "6b5c7464-e0b0-42c5-c6f5-094a958048ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t:tensor([3., 3., 3., 3., 3.])\n",
            "n:[3. 3. 3. 3. 3.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy array to Tensor"
      ],
      "metadata": {
        "id": "VgUW9v18muui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n=np.ones(5)\n",
        "t=torch.from_numpy(n)\n",
        "\n",
        "# Changes in the NumPy array reflects in the tensor.\n",
        "np.add(n,5,out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd6lZFsgmyRn",
        "outputId": "caf0bb45-edf1-426b-f2a6-6c2117533331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([6., 6., 6., 6., 6.], dtype=torch.float64)\n",
            "n: [6. 6. 6. 6. 6.]\n"
          ]
        }
      ]
    }
  ]
}